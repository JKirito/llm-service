name: llm-service

services:
  # MongoDB service
  mongodb:
    image: mongo:7.0
    container_name: llm-service-mongodb
    restart: unless-stopped
    ports:
      - "27050:27017"
    environment:
      MONGO_INITDB_DATABASE: llm-service
    volumes:
      - ./infra/mongodb_data:/data/db
      - ./infra/mongodb_config:/data/configdb
    healthcheck:
      test: ["CMD", "mongosh", "--quiet", "--eval", "db.runCommand('ping').ok", "mongodb://localhost:27017/test"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - llm-service_network

  # Redis service
  redis:
    image: redis:7-alpine
    container_name: llm-service-redis
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - ./infra/llm-service_redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - llm-service_network

  # API service (not exposed directly, accessed via Nginx)
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: llm-service-api
    restart: unless-stopped
    expose:
      - "4000"
    environment:
      # Server config
      NODE_ENV: ${NODE_ENV:-production}
      PORT: 4000
      HOST: 0.0.0.0
      API_PORT: ${API_PORT:-4000}
      
      # MongoDB config
      MONGODB_URI: mongodb://mongodb:27017/llm-service
      MONGODB_DB_NAME: ${MONGODB_DB_NAME:-llm-service}
      
      # Azure Storage config
      AZURE_STORAGE_CONNECTION_STRING: ${AZURE_STORAGE_CONNECTION_STRING}
      
      # OpenAI config
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_MODEL: ${OPENAI_MODEL:-gpt-5-nano}
      
      # Image generation config
      IMAGE_CONTAINER_NAME: ${IMAGE_CONTAINER_NAME:-generated-images}
      
      # Redis config
      REDIS_HOST: redis
      REDIS_PORT: ${REDIS_PORT:-6379}
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      REDIS_DB: ${REDIS_DB:-0}
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - llm-service_network
    healthcheck:
      test: ["CMD", "bun", "-e", "await fetch('http://localhost:4000/api/health').then(r => r.ok ? process.exit(0) : process.exit(1))"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Nginx reverse proxy with Basic Authentication
  nginx:
    image: nginx:1.25-alpine
    container_name: llm-service-nginx
    restart: unless-stopped
    ports:
      - "${NGINX_PORT:-81}:80"
      - "${NGINX_TLS_PORT:-943}:443"
    volumes:
      - type: bind
        source: ./nginx/config/nginx.conf
        target: /etc/nginx/nginx.conf
        read_only: true
      - type: bind
        source: ./nginx/config/default.conf
        target: /etc/nginx/conf.d/default.conf
        read_only: true
      - type: bind
        source: ./nginx/config/.htpasswd
        target: /etc/nginx/.htpasswd
        read_only: true
      - type: bind
        source: ./nginx/certs
        target: /etc/nginx/certs
        read_only: true
    depends_on:
      api:
        condition: service_healthy
    networks:
      - llm-service_network
    healthcheck:
      test: ["CMD", "sh", "-c", "test -f /var/run/nginx.pid"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

networks:
  llm-service_network:
    driver: bridge
